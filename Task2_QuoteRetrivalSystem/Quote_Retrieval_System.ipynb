{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEuEUoCb5ANMAAq2buvkcB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manya123-max/Assesments/blob/main/Quote_Retrieval_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1 - Package Installation:"
      ],
      "metadata": {
        "id": "myDDaqmh3j5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Required Packages\n",
        "print(\"Installing required packages...\")\n",
        "\n",
        "!pip install -q sentence-transformers datasets transformers torch torchvision torchaudio\n",
        "!pip install -q faiss-cpu pandas numpy scikit-learn\n",
        "!pip install -q gradio\n",
        "!pip install -q huggingface_hub accelerate fsspec\n",
        "\n",
        "print(\"All packages installed successfully!\")\n",
        "print(\"Please restart runtime if prompted, then proceed to Step 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUVOhcGN3jjp",
        "outputId": "99783e9b-f855-4077-cabc-84c2698d628f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "All packages installed successfully!\n",
            "Please restart runtime if prompted, then proceed to Step 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2 -Import Libraries and Setup"
      ],
      "metadata": {
        "id": "cLzTUQ5G3z8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries and Setup\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "import faiss\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTHIojRP342a",
        "outputId": "b9b433cf-3742-42fb-8a92-a8dc320101d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3- Data Processing Class"
      ],
      "metadata": {
        "id": "9u9UZ3z83_LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quote Data Processor Class\n",
        "class ColabQuoteDataProcessor:\n",
        "    def __init__(self):\n",
        "        self.dataset = None\n",
        "        self.processed_data = None\n",
        "\n",
        "    def load_data(self, max_samples=5000):\n",
        "        \"\"\"Load dataset using pandas read_json from HuggingFace\"\"\"\n",
        "        print(\" Loading dataset from HuggingFace...\")\n",
        "        try:\n",
        "            # Load dataset using the specified method\n",
        "            df = pd.read_json(\"hf://datasets/Abirate/english_quotes/quotes.jsonl\", lines=True)\n",
        "            print(f\"Dataset loaded successfully. Total size: {len(df)}\")\n",
        "\n",
        "            # Limit dataset size for Colab memory constraints\n",
        "            if len(df) > max_samples:\n",
        "                df = df.sample(n=max_samples, random_state=42).reset_index(drop=True)\n",
        "                print(f\"Randomly sampled {max_samples} quotes for Colab optimization\")\n",
        "\n",
        "            # Store as dataset format for compatibility\n",
        "            self.dataset = {\"train\": df}\n",
        "            print(f\" Dataset ready with {len(df)} quotes\")\n",
        "            return self.dataset\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error loading dataset with pandas method: {e}\")\n",
        "            print(\" Trying alternative HuggingFace datasets library...\")\n",
        "            try:\n",
        "                # Fallback to datasets library\n",
        "                from datasets import load_dataset\n",
        "                dataset = load_dataset(\"Abirate/english_quotes\")\n",
        "                df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "                if len(df) > max_samples:\n",
        "                    df = df.sample(n=max_samples, random_state=42).reset_index(drop=True)\n",
        "                    print(f\"Fallback: Limited to {max_samples} samples\")\n",
        "\n",
        "                self.dataset = {\"train\": df}\n",
        "                return self.dataset\n",
        "\n",
        "            except Exception as e2:\n",
        "                print(f\" Fallback also failed: {e2}\")\n",
        "                # Create sample data if both methods fail\n",
        "                return self.create_sample_data()\n",
        "\n",
        "    def create_sample_data(self):\n",
        "        \"\"\"Create sample data if dataset loading fails\"\"\"\n",
        "        print(\"🔧 Creating sample dataset as fallback...\")\n",
        "        sample_quotes = [\n",
        "            {\"quote\": \"The only way to do great work is to love what you do.\", \"author\": \"Steve Jobs\", \"tags\": [\"motivation\", \"work\", \"success\"]},\n",
        "            {\"quote\": \"Life is what happens to you while you're busy making other plans.\", \"author\": \"John Lennon\", \"tags\": [\"life\", \"philosophy\"]},\n",
        "            {\"quote\": \"The future belongs to those who believe in the beauty of their dreams.\", \"author\": \"Eleanor Roosevelt\", \"tags\": [\"dreams\", \"future\", \"hope\"]},\n",
        "            {\"quote\": \"It is during our darkest moments that we must focus to see the light.\", \"author\": \"Aristotle\", \"tags\": [\"hope\", \"perseverance\"]},\n",
        "            {\"quote\": \"The way to get started is to quit talking and begin doing.\", \"author\": \"Walt Disney\", \"tags\": [\"action\", \"motivation\"]},\n",
        "            {\"quote\": \"Your time is limited, don't waste it living someone else's life.\", \"author\": \"Steve Jobs\", \"tags\": [\"life\", \"authenticity\"]},\n",
        "            {\"quote\": \"If life were predictable it would cease to be life, and be without flavor.\", \"author\": \"Eleanor Roosevelt\", \"tags\": [\"life\", \"unpredictability\"]},\n",
        "            {\"quote\": \"The only impossible journey is the one you never begin.\", \"author\": \"Tony Robbins\", \"tags\": [\"journey\", \"motivation\"]},\n",
        "            {\"quote\": \"In the end, we will remember not the words of our enemies, but the silence of our friends.\", \"author\": \"Martin Luther King Jr.\", \"tags\": [\"friendship\", \"courage\"]},\n",
        "            {\"quote\": \"Success is not final, failure is not fatal: it is the courage to continue that counts.\", \"author\": \"Winston Churchill\", \"tags\": [\"success\", \"failure\", \"courage\"]}\n",
        "        ]\n",
        "\n",
        "        # Create dataset structure\n",
        "        df = pd.DataFrame(sample_quotes)\n",
        "        self.dataset = {\"train\": df}\n",
        "        print(f\"Sample dataset created with {len(df)} quotes\")\n",
        "        return self.dataset\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Clean and preprocess the dataset\"\"\"\n",
        "        print(\"Preprocessing data...\")\n",
        "\n",
        "        # Get DataFrame from dataset\n",
        "        if isinstance(self.dataset['train'], pd.DataFrame):\n",
        "            df = self.dataset['train'].copy()\n",
        "        else:\n",
        "            df = pd.DataFrame(self.dataset['train'])\n",
        "\n",
        "        print(f\"Original dataset shape: {df.shape}\")\n",
        "        print(f\"Columns: {df.columns.tolist()}\")\n",
        "\n",
        "        # Display sample data\n",
        "        print(\"Sample data:\")\n",
        "        print(df.head(2))\n",
        "\n",
        "        # Handle missing values\n",
        "        print(\"Handling missing values...\")\n",
        "        initial_size = len(df)\n",
        "        df = df.dropna(subset=['quote', 'author'])\n",
        "        print(f\"Removed {initial_size - len(df)} rows with missing quote/author\")\n",
        "\n",
        "        # Clean text\n",
        "        df['quote_clean'] = df['quote'].astype(str).str.strip()\n",
        "        df['author_clean'] = df['author'].astype(str).str.strip()\n",
        "\n",
        "        # Handle tags - check if tags column exists and handle different formats\n",
        "        if 'tags' in df.columns:\n",
        "            print(\" Processing tags column...\")\n",
        "            df['tags'] = df['tags'].apply(lambda x:\n",
        "                x if isinstance(x, list)\n",
        "                else [x] if isinstance(x, str) and x.strip()\n",
        "                else []\n",
        "            )\n",
        "        else:\n",
        "            print(\"No tags column found, creating empty tags\")\n",
        "            df['tags'] = [[] for _ in range(len(df))]\n",
        "\n",
        "        # Create search text for embedding\n",
        "        df['search_text'] = df.apply(\n",
        "            lambda row: f\"Quote: {row['quote']} Author: {row['author']} Tags: {', '.join(row['tags']) if row['tags'] else 'no tags'}\",\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        self.processed_data = df.reset_index(drop=True)\n",
        "        print(f\"Data preprocessing completed!\")\n",
        "        print(f\"Final dataset size: {len(df)} quotes\")\n",
        "        print(f\"Sample search text: {df['search_text'].iloc[0][:100]}...\")\n",
        "\n",
        "        return df\n",
        "\n",
        "print(\"Data Processing Class defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w2THIXR4Cgs",
        "outputId": "2fb3f899-6ca2-43fb-87da-ec3aa73167d9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Processing Class defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4 - Embedding Model Class"
      ],
      "metadata": {
        "id": "s7bq7iKf4WX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quote Embedding Model Class\n",
        "class ColabQuoteEmbeddingModel:\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.device = device\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the sentence transformer model\"\"\"\n",
        "        print(f\" Loading model: {self.model_name}\")\n",
        "        try:\n",
        "            self.model = SentenceTransformer(self.model_name, device=str(self.device))\n",
        "            print(f\" Model loaded successfully on {self.device}\")\n",
        "        except Exception as e:\n",
        "            print(f\" Error loading model: {e}\")\n",
        "            # Fallback to CPU\n",
        "            self.model = SentenceTransformer(self.model_name, device='cpu')\n",
        "            print(\" Loaded model on CPU\")\n",
        "        return self.model\n",
        "\n",
        "print(\" Embedding Model Class defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jXIQxF24YzQ",
        "outputId": "75b768a7-9b73-42e0-98f9-54513e71b3ff"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Embedding Model Class defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5 - RAG Pipeline Class"
      ],
      "metadata": {
        "id": "EKkvl3Ri4lm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Quote RAG Pipeline Class with Multi-hop and Analytics\n",
        "class ColabQuoteRAGPipeline:\n",
        "    def __init__(self, embedding_model):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.index = None\n",
        "        self.quotes_data = None\n",
        "        self.embeddings = None\n",
        "\n",
        "    def create_embeddings(self, quotes_data):\n",
        "        \"\"\"Create embeddings for all quotes\"\"\"\n",
        "        print(\"🔮 Creating embeddings...\")\n",
        "        self.quotes_data = quotes_data.reset_index(drop=True)\n",
        "\n",
        "        # Generate embeddings in batches to manage memory\n",
        "        texts = quotes_data['search_text'].tolist()\n",
        "        batch_size = 32\n",
        "        embeddings_list = []\n",
        "\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            batch_embeddings = self.embedding_model.encode(batch_texts, convert_to_tensor=False)\n",
        "            embeddings_list.append(batch_embeddings)\n",
        "            print(f\"Processed {min(i+batch_size, len(texts))}/{len(texts)} texts\")\n",
        "\n",
        "        self.embeddings = np.vstack(embeddings_list)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = self.embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatIP(dimension)  # Inner product for similarity\n",
        "\n",
        "        # Normalize embeddings for cosine similarity\n",
        "        faiss.normalize_L2(self.embeddings)\n",
        "        self.index.add(self.embeddings.astype('float32'))\n",
        "\n",
        "        print(f\"Index created with {self.index.ntotal} vectors\")\n",
        "        return self.index\n",
        "\n",
        "    def retrieve_quotes(self, query, top_k=5):\n",
        "        \"\"\"Retrieve relevant quotes for a query\"\"\"\n",
        "        if self.index is None:\n",
        "            raise ValueError(\"Index not created. Call create_embeddings() first.\")\n",
        "\n",
        "        # Encode query\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        # Search\n",
        "        similarities, indices = self.index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "        # Get results\n",
        "        results = []\n",
        "        for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):\n",
        "            if idx < len(self.quotes_data):\n",
        "                quote_data = self.quotes_data.iloc[idx]\n",
        "                results.append({\n",
        "                    'quote': quote_data['quote'],\n",
        "                    'author': quote_data['author'],\n",
        "                    'tags': quote_data['tags'],\n",
        "                    'similarity': float(similarity),\n",
        "                    'rank': i + 1\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def multi_hop_search(self, tags=None, author_keywords=None, content_query=None, top_k=10):\n",
        "        \"\"\"Advanced multi-hop search with filtering\"\"\"\n",
        "        filtered_data = self.quotes_data.copy()\n",
        "\n",
        "        # Filter by tags if provided\n",
        "        if tags:\n",
        "            tag_mask = filtered_data['tags'].apply(\n",
        "                lambda x: any(tag.lower() in [t.lower() for t in x] for tag in tags)\n",
        "            )\n",
        "            filtered_data = filtered_data[tag_mask]\n",
        "            print(f\"After tag filter ({tags}): {len(filtered_data)} quotes\")\n",
        "\n",
        "        # Filter by author keywords if provided\n",
        "        if author_keywords:\n",
        "            author_mask = filtered_data['author'].str.lower().str.contains(\n",
        "                '|'.join([kw.lower() for kw in author_keywords]),\n",
        "                na=False,\n",
        "                regex=True\n",
        "            )\n",
        "            filtered_data = filtered_data[author_mask]\n",
        "            print(f\"👤 After author filter ({author_keywords}): {len(filtered_data)} quotes\")\n",
        "\n",
        "        if len(filtered_data) == 0:\n",
        "            return []\n",
        "\n",
        "        # If content query provided, do semantic search on filtered data\n",
        "        if content_query:\n",
        "            # Get indices of filtered data\n",
        "            filtered_indices = filtered_data.index.tolist()\n",
        "\n",
        "            # Create temporary index with filtered embeddings\n",
        "            filtered_embeddings = self.embeddings[filtered_indices]\n",
        "            temp_index = faiss.IndexFlatIP(filtered_embeddings.shape[1])\n",
        "            faiss.normalize_L2(filtered_embeddings)\n",
        "            temp_index.add(filtered_embeddings.astype('float32'))\n",
        "\n",
        "            # Search in filtered space\n",
        "            query_embedding = self.embedding_model.encode([content_query])\n",
        "            faiss.normalize_L2(query_embedding)\n",
        "            similarities, indices = temp_index.search(query_embedding.astype('float32'), min(top_k, len(filtered_data)))\n",
        "\n",
        "            # Map back to original indices\n",
        "            results = []\n",
        "            for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):\n",
        "                if idx < len(filtered_indices):\n",
        "                    original_idx = filtered_indices[idx]\n",
        "                    quote_data = self.quotes_data.iloc[original_idx]\n",
        "                    results.append({\n",
        "                        'quote': quote_data['quote'],\n",
        "                        'author': quote_data['author'],\n",
        "                        'tags': quote_data['tags'],\n",
        "                        'similarity': float(similarity),\n",
        "                        'rank': i + 1,\n",
        "                        'filter_applied': True\n",
        "                    })\n",
        "            return results\n",
        "        else:\n",
        "            # Return filtered data without semantic search\n",
        "            results = []\n",
        "            for idx, (_, row) in enumerate(filtered_data.head(top_k).iterrows()):\n",
        "                results.append({\n",
        "                    'quote': row['quote'],\n",
        "                    'author': row['author'],\n",
        "                    'tags': row['tags'],\n",
        "                    'similarity': 1.0,  # No semantic similarity calculated\n",
        "                    'rank': idx + 1,\n",
        "                    'filter_applied': True\n",
        "                })\n",
        "            return results\n",
        "\n",
        "    def get_analytics(self):\n",
        "        \"\"\"Get analytics about the quote dataset\"\"\"\n",
        "        if self.quotes_data is None:\n",
        "            return None\n",
        "\n",
        "        analytics = {\n",
        "            'total_quotes': len(self.quotes_data),\n",
        "            'unique_authors': self.quotes_data['author'].nunique(),\n",
        "            'top_authors': self.quotes_data['author'].value_counts().head(10).to_dict(),\n",
        "            'tag_distribution': {},\n",
        "            'avg_quote_length': self.quotes_data['quote'].str.len().mean(),\n",
        "        }\n",
        "\n",
        "        # Tag analysis\n",
        "        all_tags = []\n",
        "        for tags in self.quotes_data['tags']:\n",
        "            if isinstance(tags, list):\n",
        "                all_tags.extend([tag.lower() for tag in tags])\n",
        "\n",
        "        if all_tags:\n",
        "            from collections import Counter\n",
        "            tag_counts = Counter(all_tags)\n",
        "            analytics['tag_distribution'] = dict(tag_counts.most_common(20))\n",
        "            analytics['total_unique_tags'] = len(tag_counts)\n",
        "\n",
        "        return analytics\n",
        "\n",
        "    def query(self, user_query, top_k=5):\n",
        "        \"\"\"Complete RAG query processing\"\"\"\n",
        "        retrieved_quotes = self.retrieve_quotes(user_query, top_k)\n",
        "        return retrieved_quotes\n",
        "\n",
        "print(\"Enhanced RAG Pipeline Class defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ltA2ui74i1v",
        "outputId": "a9c18aab-b08a-4252-f87a-6814715fe700"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced RAG Pipeline Class defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6 - System Initialization:"
      ],
      "metadata": {
        "id": "v0GB4FdR4u34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Process Data\n",
        "print(\"Loading and processing data...\")\n",
        "\n",
        "data_processor = ColabQuoteDataProcessor()\n",
        "dataset = data_processor.load_data(max_samples=1000)\n",
        "processed_data = data_processor.preprocess_data()\n",
        "\n",
        "print(f\" Data loaded: {len(processed_data)} quotes\")\n",
        "print(\" Ready for next step!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HA1CHmuAqr6",
        "outputId": "51e562a3-dea5-495f-e19a-1fdd09a7ace3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and processing data...\n",
            " Loading dataset from HuggingFace...\n",
            "Dataset loaded successfully. Total size: 2508\n",
            "Randomly sampled 1000 quotes for Colab optimization\n",
            " Dataset ready with 1000 quotes\n",
            "Preprocessing data...\n",
            "Original dataset shape: (1000, 3)\n",
            "Columns: ['quote', 'author', 'tags']\n",
            "Sample data:\n",
            "                                               quote                author  \\\n",
            "0  “If you never did you should. These things are...             Dr. Seuss   \n",
            "1         “Love all, trust a few, do wrong to none.”  William Shakespeare,   \n",
            "\n",
            "                             tags  \n",
            "0                         [suess]  \n",
            "1  [do-wrong, love, trust, wrong]  \n",
            "Handling missing values...\n",
            "Removed 0 rows with missing quote/author\n",
            " Processing tags column...\n",
            "Data preprocessing completed!\n",
            "Final dataset size: 1000 quotes\n",
            "Sample search text: Quote: “If you never did you should. These things are fun and fun is good.” Author: Dr. Seuss Tags: ...\n",
            " Data loaded: 1000 quotes\n",
            " Ready for next step!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Embedding Model\n",
        "print(\" Loading embedding model...\")\n",
        "\n",
        "embedding_model = ColabQuoteEmbeddingModel()\n",
        "model = embedding_model.load_model()\n",
        "\n",
        "print(\" Model loaded successfully!\")\n",
        "print(\" Ready for embedding creation!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv00JK8QAww9",
        "outputId": "a916347b-1a7c-4f27-c60c-40e507c1d9a7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loading embedding model...\n",
            " Loading model: all-MiniLM-L6-v2\n",
            " Model loaded successfully on cpu\n",
            " Model loaded successfully!\n",
            " Ready for embedding creation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RAG Pipeline and Embeddings\n",
        "print(\" Creating RAG pipeline and embeddings...\")\n",
        "print(\" This may take a few minutes depending on dataset size...\")\n",
        "\n",
        "rag_pipeline = ColabQuoteRAGPipeline(model)\n",
        "\n",
        "# Add progress tracking\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "rag_pipeline.create_embeddings(processed_data)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\" Embedding creation took {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Store in global variable for easy access\n",
        "rag_system = rag_pipeline\n",
        "\n",
        "print(\" System fully initialized!\")\n",
        "print(f\" Ready to search through {len(processed_data)} quotes\")\n",
        "print(\" Proceed to next cell for testing!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbX_jEzLA2LQ",
        "outputId": "b9b65056-5bda-45cb-b0e5-f52c888d2faf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Creating RAG pipeline and embeddings...\n",
            " This may take a few minutes depending on dataset size...\n",
            "🔮 Creating embeddings...\n",
            "Processed 32/1000 texts\n",
            "Processed 64/1000 texts\n",
            "Processed 96/1000 texts\n",
            "Processed 128/1000 texts\n",
            "Processed 160/1000 texts\n",
            "Processed 192/1000 texts\n",
            "Processed 224/1000 texts\n",
            "Processed 256/1000 texts\n",
            "Processed 288/1000 texts\n",
            "Processed 320/1000 texts\n",
            "Processed 352/1000 texts\n",
            "Processed 384/1000 texts\n",
            "Processed 416/1000 texts\n",
            "Processed 448/1000 texts\n",
            "Processed 480/1000 texts\n",
            "Processed 512/1000 texts\n",
            "Processed 544/1000 texts\n",
            "Processed 576/1000 texts\n",
            "Processed 608/1000 texts\n",
            "Processed 640/1000 texts\n",
            "Processed 672/1000 texts\n",
            "Processed 704/1000 texts\n",
            "Processed 736/1000 texts\n",
            "Processed 768/1000 texts\n",
            "Processed 800/1000 texts\n",
            "Processed 832/1000 texts\n",
            "Processed 864/1000 texts\n",
            "Processed 896/1000 texts\n",
            "Processed 928/1000 texts\n",
            "Processed 960/1000 texts\n",
            "Processed 992/1000 texts\n",
            "Processed 1000/1000 texts\n",
            "Index created with 1000 vectors\n",
            " Embedding creation took 193.89 seconds\n",
            " System fully initialized!\n",
            " Ready to search through 1000 quotes\n",
            " Proceed to next cell for testing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7 - Test Search Function"
      ],
      "metadata": {
        "id": "cSKfT1nL41Iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick Test to Verify System\n",
        "print(\" Testing the system...\")\n",
        "\n",
        "# Simple test function\n",
        "def quick_test():\n",
        "    try:\n",
        "        test_query = \"motivation\"\n",
        "        print(f\" Testing query: '{test_query}'\")\n",
        "\n",
        "        results = rag_system.query(test_query, top_k=2)\n",
        "\n",
        "        if results:\n",
        "            print(\" System is working!\")\n",
        "            for i, result in enumerate(results, 1):\n",
        "                print(f\"{i}. \\\"{result['quote'][:50]}...\\\" - {result['author']}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\" No results found\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Run the test\n",
        "if quick_test():\n",
        "    print(\" System ready for Gradio interface!\")\n",
        "else:\n",
        "    print(\" Please check previous cells for errors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRqm51l744Fy",
        "outputId": "73c3170d-ed42-431c-cd1e-82a5fb77df8f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Testing the system...\n",
            " Testing query: 'motivation'\n",
            " System is working!\n",
            "1. \"“The starting point of all achievement is DESIRE. ...\" - Napoleon Hill,\n",
            "2. \"“Of course motivation is not permanent. But then, ...\" - Zig Ziglar,\n",
            " System ready for Gradio interface!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the main search function for Gradio\n",
        "def search_quotes(query, num_results=5):\n",
        "    \"\"\"Search for quotes based on user query\"\"\"\n",
        "    print(f\" Searching for: '{query}'\")  # Debug print\n",
        "\n",
        "    if not query.strip():\n",
        "        return \" Please enter a valid query.\"\n",
        "\n",
        "    try:\n",
        "        # Query the system\n",
        "        retrieved_quotes = rag_system.query(query, top_k=num_results)\n",
        "\n",
        "        if not retrieved_quotes:\n",
        "            return f\"No quotes found for: '{query}'\"\n",
        "\n",
        "        # Format response nicely\n",
        "        response = f\" **Search Results for:** '{query}'\\n\\n\"\n",
        "\n",
        "        for i, quote in enumerate(retrieved_quotes, 1):\n",
        "            response += f\"**{i}. Quote (Similarity: {quote['similarity']:.3f})**\\n\"\n",
        "            response += f\"💬 \\\"{quote['quote']}\\\"\\n\"\n",
        "            response += f\"👤 **Author:** {quote['author']}\\n\"\n",
        "\n",
        "            if quote['tags']:\n",
        "                response += f\" **Tags:** {', '.join(quote['tags'])}\\n\"\n",
        "\n",
        "            response += \"\\n\" + \"─\" * 50 + \"\\n\\n\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Search error: {e}\")  # Debug print\n",
        "        return f\" Search failed: {str(e)}\"\n",
        "\n",
        "print(\" Search function defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kQfvdPhBKQF",
        "outputId": "16109314-94bb-4503-9889-595b452523cf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Search function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8 - Gradio Interface:"
      ],
      "metadata": {
        "id": "oGTxHm184-bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced search functions with multi-hop queries and analytics\n",
        "import json\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "def search_quotes(query, num_results=5):\n",
        "    \"\"\"Standard search for quotes based on user query\"\"\"\n",
        "    print(f\"Searching for: '{query}'\")\n",
        "\n",
        "    if not query.strip():\n",
        "        return \"Please enter a valid query.\"\n",
        "\n",
        "    try:\n",
        "        retrieved_quotes = rag_system.query(query, top_k=num_results)\n",
        "\n",
        "        if not retrieved_quotes:\n",
        "            return f\"No quotes found for: '{query}'\"\n",
        "\n",
        "        response = f\"**Search Results for:** '{query}'\\n\\n\"\n",
        "\n",
        "        for i, quote in enumerate(retrieved_quotes, 1):\n",
        "            response += f\"**{i}. Quote (Similarity: {quote['similarity']:.3f})**\\n\"\n",
        "            response += f\"💬 \\\"{quote['quote']}\\\"\\n\"\n",
        "            response += f\"👤 **Author:** {quote['author']}\\n\"\n",
        "\n",
        "            if quote['tags']:\n",
        "                response += f\"**Tags:** {', '.join(quote['tags'])}\\n\"\n",
        "\n",
        "            response += \"\\n\" + \"─\" * 50 + \"\\n\\n\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Search error: {e}\")\n",
        "        return f\"Search failed: {str(e)}\"\n",
        "\n",
        "def multi_hop_search(tags_input, author_input, content_query, num_results=10):\n",
        "    \"\"\"Advanced multi-hop search with filtering\"\"\"\n",
        "    print(f\"Multi-hop search - Tags: {tags_input}, Authors: {author_input}, Content: {content_query}\")\n",
        "\n",
        "    # Parse inputs\n",
        "    tags = [tag.strip() for tag in tags_input.split(',')] if tags_input.strip() else None\n",
        "    authors = [author.strip() for author in author_input.split(',')] if author_input.strip() else None\n",
        "    content = content_query.strip() if content_query.strip() else None\n",
        "\n",
        "    if not any([tags, authors, content]):\n",
        "        return \"Please provide at least one search criteria.\"\n",
        "\n",
        "    try:\n",
        "        results = rag_system.multi_hop_search(\n",
        "            tags=tags,\n",
        "            author_keywords=authors,\n",
        "            content_query=content,\n",
        "            top_k=num_results\n",
        "        )\n",
        "\n",
        "        if not results:\n",
        "            return \"No quotes found matching your criteria.\"\n",
        "\n",
        "        # Format response\n",
        "        response = f\"**Multi-hop Search Results**\\n\"\n",
        "        if tags:\n",
        "            response += f\"**Tags:** {', '.join(tags)}\\n\"\n",
        "        if authors:\n",
        "            response += f\"**Authors:** {', '.join(authors)}\\n\"\n",
        "        if content:\n",
        "            response += f\"**Content:** {content}\\n\"\n",
        "        response += f\"**Found:** {len(results)} quotes\\n\\n\"\n",
        "\n",
        "        for i, quote in enumerate(results, 1):\n",
        "            response += f\"**{i}.💭Quote**\"\n",
        "            if 'similarity' in quote and quote['similarity'] < 1.0:\n",
        "                response += f\" (Similarity: {quote['similarity']:.3f})\"\n",
        "            response += \"\\n\"\n",
        "            response += f\"\\\"{quote['quote']}\\\"\\n\"\n",
        "            response += f\"**👤Author:** {quote['author']}\\n\"\n",
        "\n",
        "            if quote['tags']:\n",
        "                response += f\"**Tags:** {', '.join(quote['tags'])}\\n\"\n",
        "\n",
        "            response += \"\\n\" + \"─\" * 50 + \"\\n\\n\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Multi-hop search error: {e}\")\n",
        "        return f\"Multi-hop search failed: {str(e)}\"\n",
        "\n",
        "def generate_analytics():\n",
        "    \"\"\"Generate analytics and visualizations\"\"\"\n",
        "    try:\n",
        "        analytics = rag_system.get_analytics()\n",
        "        if not analytics:\n",
        "            return \"Analytics not available\"\n",
        "\n",
        "        # Create visualizations\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "        fig.suptitle('Quote Dataset Analytics', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. Top Authors\n",
        "        top_authors = analytics['top_authors']\n",
        "        if top_authors:\n",
        "            authors = list(top_authors.keys())[:8]  # Top 8\n",
        "            counts = list(top_authors.values())[:8]\n",
        "\n",
        "            axes[0,0].barh(authors, counts, color='skyblue')\n",
        "            axes[0,0].set_title('👤 Top Authors by Quote Count')\n",
        "            axes[0,0].set_xlabel('Number of Quotes')\n",
        "\n",
        "            # Add value labels\n",
        "            for i, v in enumerate(counts):\n",
        "                axes[0,0].text(v + 0.1, i, str(v), va='center')\n",
        "\n",
        "        # 2. Tag Distribution\n",
        "        tag_dist = analytics['tag_distribution']\n",
        "        if tag_dist:\n",
        "            tags = list(tag_dist.keys())[:10]  # Top 10\n",
        "            tag_counts = list(tag_dist.values())[:10]\n",
        "\n",
        "            axes[0,1].bar(range(len(tags)), tag_counts, color='lightgreen')\n",
        "            axes[0,1].set_title('Top Tags Distribution')\n",
        "            axes[0,1].set_xlabel('Tags')\n",
        "            axes[0,1].set_ylabel('Frequency')\n",
        "            axes[0,1].set_xticks(range(len(tags)))\n",
        "            axes[0,1].set_xticklabels(tags, rotation=45, ha='right')\n",
        "\n",
        "        # 3. Quote Length Distribution\n",
        "        quote_lengths = rag_system.quotes_data['quote'].str.len()\n",
        "        axes[1,0].hist(quote_lengths, bins=30, alpha=0.7, color='coral')\n",
        "        axes[1,0].set_title('Quote Length Distribution')\n",
        "        axes[1,0].set_xlabel('Quote Length (characters)')\n",
        "        axes[1,0].set_ylabel('Frequency')\n",
        "        axes[1,0].axvline(analytics['avg_quote_length'], color='red', linestyle='--',\n",
        "                         label=f'Avg: {analytics[\"avg_quote_length\"]:.0f}')\n",
        "        axes[1,0].legend()\n",
        "\n",
        "        # 4. Summary Stats\n",
        "        axes[1,1].axis('off')\n",
        "        summary_text = f\"\"\"\n",
        "        Dataset Summary\n",
        "\n",
        "        Total Quotes: {analytics['total_quotes']:,}\n",
        "        Unique Authors: {analytics['unique_authors']:,}\n",
        "        Unique Tags: {analytics.get('total_unique_tags', 'N/A')}\n",
        "        Avg Quote Length: {analytics['avg_quote_length']:.0f} chars\n",
        "\n",
        "        Most Prolific Author:\n",
        "        {list(top_authors.keys())[0] if top_authors else 'N/A'}\n",
        "        ({list(top_authors.values())[0] if top_authors else 0} quotes)\n",
        "\n",
        "        Most Common Tag:\n",
        "        {list(tag_dist.keys())[0] if tag_dist else 'N/A'}\n",
        "        ({list(tag_dist.values())[0] if tag_dist else 0} occurrences)\n",
        "        \"\"\"\n",
        "\n",
        "        axes[1,1].text(0.1, 0.9, summary_text, transform=axes[1,1].transAxes,\n",
        "                      fontsize=12, verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return f\"Analytics generated! Check the visualizations above.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Analytics error: {e}\")\n",
        "        return f\"Analytics generation failed: {str(e)}\"\n",
        "\n",
        "def prepare_download_data(search_results_text, search_type=\"standard\"):\n",
        "    \"\"\"Prepare search results for JSON download\"\"\"\n",
        "    try:\n",
        "        # This is a simplified version - in a full implementation,\n",
        "        # you'd want to store the actual search results data structure\n",
        "        download_data = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"search_type\": search_type,\n",
        "            \"results_text\": search_results_text,\n",
        "            \"metadata\": {\n",
        "                \"total_quotes_in_db\": len(rag_system.quotes_data) if rag_system.quotes_data is not None else 0,\n",
        "                \"search_timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Convert to JSON string\n",
        "        json_str = json.dumps(download_data, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return json_str\n",
        "\n",
        "    except Exception as e:\n",
        "        return f'{{\"error\": \"Failed to prepare download: {str(e)}\"}}'\n",
        "\n",
        "print(\"Enhanced search functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7ozVZJB5BkR",
        "outputId": "28dd8b1e-e147-4308-e5ea-a197eb4b8e6c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced search functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9 - Launch Interface"
      ],
      "metadata": {
        "id": "J6IKZgXt5J0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Gradio Interface without analytics\n",
        "def create_enhanced_interface():\n",
        "    \"\"\"Create enhanced Gradio interface with multi-hop search (no analytics)\"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"Advanced Quote Search System\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"# Advanced Quote Search System\")\n",
        "        gr.Markdown(\"*Semantic search with multi-hop queries and downloads*\")\n",
        "\n",
        "        with gr.Tabs():\n",
        "            # Tab 1: Standard Search\n",
        "            with gr.TabItem(\"Standard Search\"):\n",
        "                gr.Markdown(\"### Simple semantic search for quotes\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=4):\n",
        "                        query_input = gr.Textbox(\n",
        "                            label=\"Enter your search query\",\n",
        "                            placeholder=\"e.g., 'quotes about love', 'motivation quotes', 'Steve Jobs quotes'\",\n",
        "                            lines=2\n",
        "                        )\n",
        "                    with gr.Column(scale=1):\n",
        "                        num_results = gr.Slider(\n",
        "                            label=\"Number of results\",\n",
        "                            minimum=1,\n",
        "                            maximum=15,\n",
        "                            value=5,\n",
        "                            step=1\n",
        "                        )\n",
        "\n",
        "                search_btn = gr.Button(\"Search Quotes\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                standard_results = gr.Markdown(\n",
        "                    label=\"Search Results\",\n",
        "                    value=\"Enter a query and click 'Search Quotes' to see results.\"\n",
        "                )\n",
        "\n",
        "                # Download section for standard search\n",
        "                with gr.Row():\n",
        "                    download_std_btn = gr.Button(\"Prepare Download\", size=\"sm\")\n",
        "                    download_std_file = gr.File(label=\"Download Results (JSON)\", visible=False)\n",
        "\n",
        "                search_btn.click(\n",
        "                    search_quotes,\n",
        "                    inputs=[query_input, num_results],\n",
        "                    outputs=standard_results\n",
        "                )\n",
        "\n",
        "                download_std_btn.click(\n",
        "                    lambda results: prepare_download_data(results, \"standard\"),\n",
        "                    inputs=standard_results,\n",
        "                    outputs=gr.Textbox(visible=False)\n",
        "                ).then(\n",
        "                    lambda json_data: gr.File.update(\n",
        "                        value=json_data,\n",
        "                        visible=True,\n",
        "                        filename=f\"quote_search_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "                    ),\n",
        "                    inputs=gr.Textbox(visible=False),\n",
        "                    outputs=download_std_file\n",
        "                )\n",
        "\n",
        "            # Tab 2: Multi-hop Search\n",
        "            with gr.TabItem(\"Multi-hop Search\"):\n",
        "                gr.Markdown(\"### Advanced search with multiple criteria\")\n",
        "                gr.Markdown(\"*Search by tags, authors, and content simultaneously*\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        tags_input = gr.Textbox(\n",
        "                            label=\"Tags (comma-separated)\",\n",
        "                            placeholder=\"e.g., life, love, motivation\",\n",
        "                            lines=1\n",
        "                        )\n",
        "                        author_input = gr.Textbox(\n",
        "                            label=\"Author keywords (comma-separated)\",\n",
        "                            placeholder=\"e.g., Einstein, Jobs, Roosevelt\",\n",
        "                            lines=1\n",
        "                        )\n",
        "                        content_input = gr.Textbox(\n",
        "                            label=\"Content query\",\n",
        "                            placeholder=\"e.g., overcoming challenges\",\n",
        "                            lines=2\n",
        "                        )\n",
        "                    with gr.Column(scale=1):\n",
        "                        multi_num_results = gr.Slider(\n",
        "                            label=\"Max results\",\n",
        "                            minimum=1,\n",
        "                            maximum=20,\n",
        "                            value=10,\n",
        "                            step=1\n",
        "                        )\n",
        "\n",
        "                multi_search_btn = gr.Button(\"Multi-hop Search\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                multi_results = gr.Markdown(\n",
        "                    label=\"Multi-hop Search Results\",\n",
        "                    value=\"Configure your search criteria above and click 'Multi-hop Search'.\"\n",
        "                )\n",
        "\n",
        "                # Download section for multi-hop search\n",
        "                with gr.Row():\n",
        "                    download_multi_btn = gr.Button(\"Prepare Download\", size=\"sm\")\n",
        "                    download_multi_file = gr.File(label=\"Download Results (JSON)\", visible=False)\n",
        "\n",
        "                multi_search_btn.click(\n",
        "                    multi_hop_search,\n",
        "                    inputs=[tags_input, author_input, content_input, multi_num_results],\n",
        "                    outputs=multi_results\n",
        "                )\n",
        "\n",
        "                download_multi_btn.click(\n",
        "                    lambda results: prepare_download_data(results, \"multi_hop\"),\n",
        "                    inputs=multi_results,\n",
        "                    outputs=gr.Textbox(visible=False)\n",
        "                ).then(\n",
        "                    lambda json_data: gr.File.update(\n",
        "                        value=json_data,\n",
        "                        visible=True,\n",
        "                        filename=f\"multihop_search_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "                    ),\n",
        "                    inputs=gr.Textbox(visible=False),\n",
        "                    outputs=download_multi_file\n",
        "                )\n",
        "\n",
        "                # Examples for multi-hop\n",
        "                gr.Markdown(\"### Multi-hop Examples:\")\n",
        "                with gr.Row():\n",
        "                    gr.Button(\"Life + Love quotes\", size=\"sm\").click(\n",
        "                        lambda: (\"life, love\", \"\", \"\"),\n",
        "                        outputs=[tags_input, author_input, content_input]\n",
        "                    )\n",
        "                    gr.Button(\"Einstein quotes about science\", size=\"sm\").click(\n",
        "                        lambda: (\"\", \"Einstein\", \"science and discovery\"),\n",
        "                        outputs=[tags_input, author_input, content_input]\n",
        "                    )\n",
        "                    gr.Button(\"20th century motivation\", size=\"sm\").click(\n",
        "                        lambda: (\"motivation, success\", \"Roosevelt, Churchill, Jobs\", \"\"),\n",
        "                        outputs=[tags_input, author_input, content_input]\n",
        "                    )\n",
        "\n",
        "        # Quick Examples (bottom of interface)\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### Quick Start Examples\")\n",
        "\n",
        "        example_queries = [\n",
        "            \"quotes about perseverance\",\n",
        "            \"wisdom and knowledge\",\n",
        "            \"Steve Jobs innovation\",\n",
        "            \"life philosophy\",\n",
        "            \"success and failure\",\n",
        "            \"love and relationships\"\n",
        "        ]\n",
        "\n",
        "        with gr.Row():\n",
        "            for query in example_queries[:3]:\n",
        "                gr.Button(query, size=\"sm\").click(\n",
        "                    lambda q=query: q, outputs=query_input\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            for query in example_queries[3:]:\n",
        "                gr.Button(query, size=\"sm\").click(\n",
        "                    lambda q=query: q, outputs=query_input\n",
        "                )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Create the enhanced interface\n",
        "print(\"Creating enhanced Gradio interface...\")\n",
        "demo = create_enhanced_interface()\n",
        "print(\"Enhanced interface created successfully!\")\n",
        "\n",
        "# Fix for port error - try multiple ports\n",
        "def launch_with_fallback_port(demo, start_port=7860):\n",
        "    \"\"\"Launch demo with fallback ports if the default is occupied\"\"\"\n",
        "    max_attempts = 10\n",
        "\n",
        "    for i in range(max_attempts):\n",
        "        try:\n",
        "            port = start_port + i\n",
        "            print(f\"Attempting to launch on port {port}...\")\n",
        "\n",
        "            demo.launch(\n",
        "                share=True,  # Creates public URL for Colab\n",
        "                server_name=\"0.0.0.0\",  # Allow external connections\n",
        "                server_port=port,\n",
        "                show_error=True,  # Show detailed errors\n",
        "                quiet=False  # Show startup logs\n",
        "            )\n",
        "            print(f\"SUCCESS! Interface launched on port {port}\")\n",
        "            break\n",
        "\n",
        "        except OSError as e:\n",
        "            if \"Cannot find empty port\" in str(e) and i < max_attempts - 1:\n",
        "                print(f\"Port {port} is busy, trying next port...\")\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"Failed to launch after {max_attempts} attempts\")\n",
        "                print(\"Try restarting your runtime or manually specify a different port\")\n",
        "                raise e\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error: {e}\")\n",
        "            raise e\n",
        "\n",
        "# Launch the interface with port fallback\n",
        "print(\"Launching interface...\")\n",
        "print(\"The interface will be accessible via the public URL below\")\n",
        "print(\"Click the link to open the Quote Search System\")\n",
        "\n",
        "try:\n",
        "    launch_with_fallback_port(demo)\n",
        "    print(\"SUCCESS! Interface is now running!\")\n",
        "except Exception as e:\n",
        "    print(f\"Launch failed: {e}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Try restarting your Colab runtime\")\n",
        "    print(\"2. Run the cleanup cell (Cell 10) first\")\n",
        "    print(\"3. Then re-run cells 1-9\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "oOe1WrOC5JDF",
        "outputId": "fa02afd5-fa7f-4f7b-ca8b-bbf9e4d0b165"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating enhanced Gradio interface...\n",
            "Enhanced interface created successfully!\n",
            "Launching interface...\n",
            "The interface will be accessible via the public URL below\n",
            "Click the link to open the Quote Search System\n",
            "Attempting to launch on port 7860...\n",
            "Port 7860 is busy, trying next port...\n",
            "Attempting to launch on port 7861...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://219039497a88332166.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://219039497a88332166.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS! Interface launched on port 7861\n",
            "SUCCESS! Interface is now running!\n"
          ]
        }
      ]
    }
  ]
}
